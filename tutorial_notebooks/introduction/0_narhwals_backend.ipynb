{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TemporalScope Tutorial: Backend-Agnostic Functions Using Narwhals\n",
    "\n",
    "### Purpose\n",
    "This tutorial demonstrates how **TemporalScope** can leverage **Narwhals** to support backend-agnostic data operations. By building backend-agnostic functions, TemporalScope enables compatibility across multiple popular data processing libraries including **Pandas**, **Modin**, **Polars**, and **PyArrow**.\n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Create a Sample Dataset**: We begin by creating a synthetic dataset in Pandas, which we will transform and test for compatibility across Modin, Polars, and PyArrow.\n",
    "2. **Implement a Narwhals-Decorated Function**: With Narwhals’ `@narwhalify` decorator, we can create a backend-agnostic function that performs simple operations like aggregation or column transformations without needing to rewrite the logic for each backend.\n",
    "3. **Run Compatibility Tests**: Finally, we test the function across all supported backends to verify smooth execution across Pandas, Modin, Polars, and PyArrow.\n",
    "\n",
    "### Supported TemporalScope Backends\n",
    "The TemporalScope core API is designed to be compatible with a wide range of popular DataFrame backends. Here are the currently supported backends:\n",
    "\n",
    "- **Pandas**: General-purpose data processing in Python, compatible with Narwhals.\n",
    "- **Modin**: Parallelized Pandas-like library for distributed data processing.\n",
    "- **Polars**: Rust-based, highly efficient DataFrame library for analytics.\n",
    "- **PyArrow**: Apache Arrow-based DataFrame supporting large, in-memory data processing.\n",
    "- **Dask**: Distributed DataFrame library for parallel computation on large datasets.\n",
    "\n",
    "These backends allow TemporalScope users to scale or optimize their workflows without modifying code.\n",
    "\n",
    "### Advantages of Using Narwhals\n",
    "\n",
    "- **Uniform API**: The `@narwhalify` decorator from Narwhals creates a seamless backend-neutral execution environment, allowing developers to use the same function across multiple DataFrame libraries.\n",
    "- **Enhanced Compatibility**: Narwhals optimizes how data is accessed and manipulated across backends, ensuring the syntax and functions used are supported by each compatible backend.\n",
    "- **Simplified Codebase**: By using Narwhals for backend-agnostic functions, TemporalScope’s core logic can remain generalized, reducing code duplication and maintenance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 0: Backend Compatibility with TemporalScope and Narwhals\n",
    "\n",
    "This example demonstrates a basic setup to ensure compatibility across various DataFrame backends using TemporalScope’s backend utilities and Narwhals.\n",
    "\n",
    "1. **Check Supported Backends**:\n",
    "   - Retrieve and validate the supported backends with `get_temporalscope_backends()` and `validate_backend()` for `pandas`, `modin`, `polars`, and `pyarrow`.\n",
    "2. **Run Narwhals-Compatible Operation**:\n",
    "   - Define a backend-agnostic function with `@narwhalify` to aggregate basic column statistics, showcasing Narwhals’ compatibility layer across supported backends.\n",
    "3. **Compare Results Across Backends**:\n",
    "- Execute the Narwhals-compatible function on DataFrames from different backends and compare the results to ensure consistency across implementations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'validate_backend' from partially initialized module 'temporalscope.core.core_utils' (most likely due to a circular import) (/home/philip-research/Documents/GITHUB/TemporalScope/src/temporalscope/core/core_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnw\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtemporalscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     get_temporalscope_backends,\n\u001b[1;32m      6\u001b[0m     get_narwhals_backends,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrameT\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Constants\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GITHUB/TemporalScope/src/temporalscope/core/core_utils.py:112\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Implementation\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrameT  \u001b[38;5;66;03m# Import FrameT from Narwhals for unified type hinting\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtemporalscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_backend, convert_to_backend, get_temporalscope_backends\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmodin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'validate_backend' from partially initialized module 'temporalscope.core.core_utils' (most likely due to a circular import) (/home/philip-research/Documents/GITHUB/TemporalScope/src/temporalscope/core/core_utils.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import narwhals as nw\n",
    "from temporalscope.core.core_utils import (\n",
    "    get_temporalscope_backends,\n",
    "    get_narwhals_backends,\n",
    ")\n",
    "from narwhals.typing import FrameT\n",
    "\n",
    "# Constants\n",
    "NUM_ROWS = 200\n",
    "SEED = 42\n",
    "\n",
    "# Step 1: Generate sample time-series data in Pandas\n",
    "np.random.seed(SEED)\n",
    "date_range = pd.date_range(start=\"2023-01-01\", periods=NUM_ROWS, freq=\"D\")\n",
    "data = pd.DataFrame({\n",
    "    \"datetime\": date_range,\n",
    "    \"feature_1\": np.random.rand(NUM_ROWS),\n",
    "    \"feature_2\": np.random.randn(NUM_ROWS)\n",
    "})\n",
    "\n",
    "# Step 2: Define a Narwhals-compatible function using @narwhalify\n",
    "@nw.narwhalify\n",
    "def test_narwhal_conversion(df: FrameT) -> FrameT:\n",
    "    \"\"\"Perform Narwhals operations on a compatible DataFrame.\"\"\"\n",
    "    return df.select(\n",
    "        feature_1_sum=nw.col(\"feature_1\").sum(),\n",
    "        feature_2_mean=nw.col(\"feature_2\").mean()\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the Narwhals operation\n",
    "    print(\"Original DataFrame Type:\", type(data))\n",
    "    result_df = test_narwhal_conversion(data)\n",
    "    print(\"Result of Narwhals operation:\\n\", result_df)\n",
    "    \n",
    "    # Step 3: Check backend support using TemporalScope core_utils\n",
    "    print(\"\\n== TemporalScope and Narwhals Backend Checks ==\")\n",
    "    temporalscope_backends = get_temporalscope_backends()\n",
    "    print(\"Supported TemporalScope Backends:\", temporalscope_backends)\n",
    "\n",
    "    narwhals_backends = get_narwhals_backends()\n",
    "    print(\"Supported Narwhals Backends:\", narwhals_backends)\n",
    "\n",
    "    # Validate if 'pandas' backend is supported\n",
    "    try:\n",
    "        validate_backend('pandas')\n",
    "        print(\"Pandas backend validation: PASSED\")\n",
    "    except Exception as e:\n",
    "        print(\"Pandas backend validation: FAILED\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import narwhals as nw\n",
    "from narwhals.typing import FrameT\n",
    "\n",
    "# Constants\n",
    "NUM_ROWS = 100\n",
    "SEED = 42\n",
    "\n",
    "# Step 1: Generate sample time-series data in Pandas\n",
    "np.random.seed(SEED)\n",
    "date_range = pd.date_range(start=\"2023-01-01\", periods=NUM_ROWS, freq=\"D\")\n",
    "data_pandas = pd.DataFrame({\n",
    "    \"datetime\": date_range,\n",
    "    \"feature_1\": np.random.rand(NUM_ROWS),\n",
    "    \"feature_2\": np.random.randn(NUM_ROWS)\n",
    "})\n",
    "\n",
    "# Convert Pandas DataFrame to Polars\n",
    "data_polars = pl.DataFrame(data_pandas)\n",
    "\n",
    "# Utility Functions\n",
    "def is_timestamp_column(df: FrameT, col: str) -> bool:\n",
    "    \"\"\"Check if a column is timestamp-like.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Column '{col}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    try:\n",
    "        if isinstance(df, pd.DataFrame):  # Pandas check\n",
    "            return pd.api.types.is_datetime64_any_dtype(df[col])\n",
    "        elif isinstance(df, pl.DataFrame):  # Polars check\n",
    "            return str(df.schema[col]).startswith(\"Datetime\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported DataFrame type: {type(df)}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error while checking column type: {e}\")\n",
    "\n",
    "def get_backend_info(df: FrameT) -> str:\n",
    "    \"\"\"Determine the original backend of the DataFrame.\"\"\"\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        return \"pandas\"\n",
    "    elif isinstance(df, pl.DataFrame):\n",
    "        return \"polars\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Narwhals Function\n",
    "@nw.narwhalify\n",
    "def test_narwhal_conversion(df: FrameT) -> FrameT:\n",
    "    \"\"\"Perform Narwhals operations on a compatible DataFrame.\"\"\"\n",
    "    return df.select(\n",
    "        feature_1_sum=nw.col(\"feature_1\").sum(),\n",
    "        feature_2_mean=nw.col(\"feature_2\").mean()\n",
    "    )\n",
    "\n",
    "# Main Test Logic\n",
    "def run_tests(data: FrameT, backend_name: str):\n",
    "    print(f\"\\n=== Testing {backend_name} Backend ===\")\n",
    "    \n",
    "    # Original Backend\n",
    "    try:\n",
    "        original_backend = get_backend_info(data)\n",
    "        print(\"Original DataFrame Backend:\", original_backend)\n",
    "    except Exception as e:\n",
    "        print(\"Error determining backend:\", e)\n",
    "\n",
    "    # Timestamp Check\n",
    "    try:\n",
    "        is_timestamp = is_timestamp_column(data, \"datetime\")\n",
    "        print(\"Is 'datetime' timestamp-like?\", is_timestamp)\n",
    "    except Exception as e:\n",
    "        print(\"Timestamp check failed:\", e)\n",
    "\n",
    "    # Narwhals Operation\n",
    "    try:\n",
    "        result_df = test_narwhal_conversion(data)\n",
    "        print(\"\\nResult of Narwhals operation:\\n\", result_df)\n",
    "    except Exception as e:\n",
    "        print(\"Narwhals operation failed:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with Pandas\n",
    "    run_tests(data_pandas, \"Pandas\")\n",
    "\n",
    "    # Test with Polars\n",
    "    run_tests(data_polars, \"Polars\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Using Narwhals for Backend-Agnostic Null Check\n",
    "\n",
    "Narwhals enables robust, backend-agnostic data processing, which can streamline workflows across Pandas, Modin, Polars, and PyArrow backends. Here’s how to create a simple backend-agnostic null-check function and test it across multiple frameworks.\n",
    "\n",
    "1. **Create a Synthetic DataFrame**:\n",
    "   - Use a function like `generate_data_time_series()` to create a manageable dataset, with defaults that allow flexibility for larger data sizes.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Function**:\n",
    "   - Use the `@narwhalify` decorator to convert standard DataFrame operations to backend-agnostic ones.\n",
    "   - For example, `check_nulls_nw()` checks for null values without being tied to a specific backend.\n",
    "\n",
    "3. **Test Across Multiple Backends**:\n",
    "   - Convert the DataFrame to various backends and execute the Narwhals function to verify compatibility and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import dask.dataframe as dd\n",
    "import narwhals as nw\n",
    "import numpy as np\n",
    "from narwhals.typing import FrameT\n",
    "from temporalscope.core.core_utils import TEMPORALSCOPE_CORE_BACKEND_TYPES, SupportedTemporalDataFrame\n",
    "\n",
    "NUM_ROWS = 100\n",
    "SEED = 42\n",
    "\n",
    "def generate_data(num_rows: int = NUM_ROWS, backend: str = \"pandas\") -> SupportedTemporalDataFrame:\n",
    "    \"\"\"Generates a time-series DataFrame with specified backend, adding features and a target.\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    data = pd.DataFrame({\n",
    "        \"datetime\": pd.date_range(start=\"2023-01-01\", periods=num_rows, freq=\"D\")\n",
    "    })\n",
    "    \n",
    "    # Generate 5 features\n",
    "    for i in range(5):\n",
    "        data[f\"feature_{i+1}\"] = np.random.randn(num_rows)\n",
    "    data[\"target\"] = np.random.rand(num_rows)\n",
    "    data.loc[0, 'feature_1'] = None  # Inject a null value for testing\n",
    "\n",
    "    # Convert to specified backend\n",
    "    if backend == \"modin\":\n",
    "        return mpd.DataFrame(data)\n",
    "    elif backend == \"polars\":\n",
    "        return pl.DataFrame(data)\n",
    "    elif backend == \"pyarrow\":\n",
    "        return pa.Table.from_pandas(data)\n",
    "    elif backend == \"dask\":\n",
    "        return dd.from_pandas(data, npartitions=2)\n",
    "    return data\n",
    "\n",
    "@nw.narwhalify\n",
    "def check_nulls_nw(df: FrameT) -> FrameT:\n",
    "    \"\"\"Checks for null values in 'feature_1' in a backend-agnostic way using Narwhals.\"\"\"\n",
    "    return df.select(\n",
    "        has_nulls=nw.col(\"feature_1\").is_null().any()\n",
    "    )\n",
    "\n",
    "def test_backends():\n",
    "    \"\"\"Tests `check_nulls_nw` on all supported TemporalScope backends.\"\"\"\n",
    "    results = []\n",
    "    for backend_name in TEMPORALSCOPE_CORE_BACKEND_TYPES.keys():\n",
    "        data_df = generate_data(backend=backend_name)\n",
    "        try:\n",
    "            has_nulls = check_nulls_nw(data_df)\n",
    "            results.append({\n",
    "                \"Backend\": backend_name,\n",
    "                \"Has Nulls\": has_nulls,\n",
    "                \"Executed Successfully\": True\n",
    "            })\n",
    "            print(f\"{backend_name} -> Executed Successfully, Has Nulls: {has_nulls}\\n\")\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"Backend\": backend_name,\n",
    "                \"Executed Successfully\": False,\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "            print(f\"{backend_name} -> Failed with error: {e}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    backend_results = test_backends()\n",
    "    print(\"\\n--- Summary of Backend Compatibility ---\")\n",
    "    for result in backend_results:\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import dask.dataframe as dd\n",
    "import narwhals as nw\n",
    "from narwhals.typing import FrameT\n",
    "import numpy as np\n",
    "from temporalscope.core.core_utils import TEMPORALSCOPE_CORE_BACKEND_TYPES\n",
    "\n",
    "# Constants\n",
    "NUM_ROWS = 100\n",
    "SEED = 42\n",
    "\n",
    "# Data generator function\n",
    "def generate_data(num_rows: int = NUM_ROWS, backend: str = \"pandas\") -> pd.DataFrame:\n",
    "    \"\"\"Generates a time-series DataFrame with multiple features and a target column.\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    data = pd.DataFrame({\n",
    "        \"datetime\": pd.date_range(start=\"2023-01-01\", periods=num_rows, freq=\"D\"),\n",
    "        **{f\"feature_{i}\": np.random.rand(num_rows) for i in range(1, 6)},  # Generating 5 random features\n",
    "        \"target\": np.random.randint(0, 100, num_rows)  # Random integer target\n",
    "    })\n",
    "    data.loc[0, 'feature_1'] = None  # Injecting a null value for testing\n",
    "    \n",
    "    # Convert to the specified backend\n",
    "    if backend == \"modin\":\n",
    "        return mpd.DataFrame(data)\n",
    "    elif backend == \"polars\":\n",
    "        return pl.DataFrame(data)\n",
    "    elif backend == \"pyarrow\":\n",
    "        return pa.Table.from_pandas(data)\n",
    "    elif backend == \"dask\":\n",
    "        return dd.from_pandas(data, npartitions=2)\n",
    "    return data  # Default to Pandas DataFrame\n",
    "\n",
    "# Narwhals-compatible function for summary statistics\n",
    "@nw.narwhalify\n",
    "def calculate_summaries_nw(df: FrameT) -> FrameT:\n",
    "    \"\"\"Calculates mean, sum, and standard deviation for each feature using Narwhals.\"\"\"\n",
    "    expressions = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith(\"feature_\"):\n",
    "            expressions.extend([\n",
    "                nw.col(col).mean().alias(f\"{col}_mean\"),\n",
    "                nw.col(col).sum().alias(f\"{col}_sum\"),\n",
    "                nw.col(col).std().alias(f\"{col}_std\")\n",
    "            ])\n",
    "    return df.select(*expressions)\n",
    "\n",
    "# Testing function across all backends\n",
    "def test_backends():\n",
    "    \"\"\"Tests `calculate_summaries_nw` on all supported TemporalScope backends.\"\"\"\n",
    "    results = []\n",
    "    for backend_name in TEMPORALSCOPE_CORE_BACKEND_TYPES.keys():\n",
    "        data_df = generate_data(backend=backend_name)\n",
    "        try:\n",
    "            summaries = calculate_summaries_nw(data_df)\n",
    "            results.append({\n",
    "                \"Backend\": backend_name,\n",
    "                \"Summaries\": summaries,\n",
    "                \"Executed Successfully\": True\n",
    "            })\n",
    "            print(f\"{backend_name} -> Executed Successfully, Summaries:\\n{summaries}\\n\")\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"Backend\": backend_name,\n",
    "                \"Executed Successfully\": False,\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "            print(f\"{backend_name} -> Failed with error: {e}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the backend compatibility tests\n",
    "    backend_results = test_backends()\n",
    "    print(\"\\n--- Summary of Backend Compatibility ---\")\n",
    "    for result in backend_results:\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Calculating Summary Statistics in a Backend-Agnostic Manner\n",
    "\n",
    "This example demonstrates **Narwhals**' ability to calculate summary statistics (mean, sum, standard deviation) across TemporalScope’s supported backends—**Pandas**, **Modin**, **Polars**, **PyArrow**, and **Dask**—with a backend-agnostic function that leverages Narwhals’ compatibility layer. \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic time-series DataFrame with multiple features and a target column. This dataset is compatible with multiple backends and provides the basis for backend-agnostic operations.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Summary Function**:\n",
    "   - `calculate_summaries_nw()` uses the `@narwhalify` decorator to compute mean, sum, and standard deviation for each feature in a backend-agnostic manner.\n",
    "\n",
    "3. **Understanding Lazy vs. Eager Evaluation**:\n",
    "   - **Lazy Evaluation** (Polars, Dask): Allows efficient, optimized computation by delaying operations until results are explicitly requested, like with `.collect()`. Narwhals supports lazy evaluation for backends like Polars, automatically handling eager execution where needed.\n",
    "   - **Eager Evaluation** (Pandas, Modin, PyArrow): Calculates results immediately, useful for smaller datasets or immediate result retrieval.\n",
    "   - Narwhals adapts between lazy and eager modes based on backend needs, ensuring that computations are handled correctly even across large and distributed datasets.\n",
    "\n",
    "4. **Test Across Multiple Backends**:\n",
    "   - The function is tested across the TemporalScope-supported backends, with each backend returning summary statistics in its native structure.\n",
    "   - Results vary slightly in format: Pandas and Modin return DataFrames, PyArrow returns a `Table`, Polars provides its own optimized `DataFrame` structure, and Dask shows results as a Dask DataFrame structure.\n",
    "\n",
    "This example showcases Narwhals’ seamless support for multi-backend compatibility, optimizing data operations across frameworks without modifying the core logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Scaling and Lagging Features in a Backend-Agnostic Manner\n",
    "\n",
    "In this example, we demonstrate **Narwhals**’ capability to apply scaling and lag transformations across TemporalScope's supported backends. This approach is beneficial for time-series analysis, where lagging can reveal important sequential dependencies. Narwhals allows us to scale and lag feature columns consistently across multiple frameworks, maintaining a unified codebase.\n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Generate Synthetic Data Across Backends**:\n",
    "   - Using `generate_data()`, we create a synthetic DataFrame with multiple features and a target column, which can be applied to each backend for testing.\n",
    "\n",
    "2. **Define a Narwhals-Compatible Scaling and Lagging Function**:\n",
    "   - `scale_and_lag_features_nw()` applies scaling and lagging transformations to each feature column in a backend-agnostic manner. Scaling standardizes each feature, and lagging shifts values by a defined number of steps, revealing sequential dependencies.\n",
    "\n",
    "3. **Test Across Multiple Backends**:\n",
    "   - Run the function on each backend, returning results in the native format for each. This verifies compatibility and consistent application of transformations across Pandas, Modin, Polars, PyArrow, and Dask backends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import dask.dataframe as dd\n",
    "import narwhals as nw\n",
    "from narwhals.typing import FrameT\n",
    "import numpy as np\n",
    "from temporalscope.core.core_utils import TEMPORALSCOPE_CORE_BACKEND_TYPES\n",
    "\n",
    "# Constants\n",
    "NUM_ROWS = 100\n",
    "SEED = 42\n",
    "\n",
    "# Data generator function\n",
    "def generate_data(num_rows: int = NUM_ROWS, backend: str = \"pandas\") -> pd.DataFrame:\n",
    "    \"\"\"Generates a time-series DataFrame with multiple features and a target column.\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    data = pd.DataFrame({\n",
    "        \"datetime\": pd.date_range(start=\"2023-01-01\", periods=num_rows, freq=\"D\"),\n",
    "        **{f\"feature_{i}\": np.random.rand(num_rows) for i in range(1, 6)},  # Generating 5 random features\n",
    "        \"target\": np.random.randint(0, 100, num_rows)  # Random integer target\n",
    "    })\n",
    "    \n",
    "    # Convert to the specified backend\n",
    "    if backend == \"modin\":\n",
    "        return mpd.DataFrame(data)\n",
    "    elif backend == \"polars\":\n",
    "        return pl.DataFrame(data)\n",
    "    elif backend == \"pyarrow\":\n",
    "        return pa.Table.from_pandas(data)\n",
    "    elif backend == \"dask\":\n",
    "        return dd.from_pandas(data, npartitions=2)\n",
    "    return data  # Default to Pandas DataFrame\n",
    "\n",
    "# Narwhals-compatible function for scaling and lagging features\n",
    "@nw.narwhalify\n",
    "def scale_and_lag_features_nw(df: FrameT, lag_steps: int = 3) -> FrameT:\n",
    "    \"\"\"Applies scaling and lagging to each feature in a backend-agnostic way using Narwhals.\"\"\"\n",
    "    transformations = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith(\"feature_\"):\n",
    "            transformations.extend([\n",
    "                ((nw.col(col) - nw.col(col).mean()) / nw.col(col).std()).alias(f\"{col}_scaled\"),\n",
    "                nw.col(col).shift(lag_steps).alias(f\"{col}_lag{lag_steps}\")\n",
    "            ])\n",
    "    return df.with_columns(*transformations)\n",
    "\n",
    "# Testing function across all backends\n",
    "def test_backends():\n",
    "    \"\"\"Tests `scale_and_lag_features_nw` on all supported TemporalScope backends.\"\"\"\n",
    "    results = []\n",
    "    for backend_name in TEMPORALSCOPE_CORE_BACKEND_TYPES.keys():\n",
    "        data_df = generate_data(backend=backend_name)\n",
    "        try:\n",
    "            transformed_df = scale_and_lag_features_nw(data_df)\n",
    "            results.append({\n",
    "                \"Backend\": backend_name,\n",
    "                \"Transformed Data\": transformed_df,\n",
    "                \"Executed Successfully\": True\n",
    "            })\n",
    "            print(f\"{backend_name} -> Executed Successfully, Transformed Data:\\n{transformed_df}\\n\")\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"Backend\": backend_name,\n",
    "                \"Executed Successfully\": False,\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "            print(f\"{backend_name} -> Failed with error: {e}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the backend compatibility tests\n",
    "    backend_results = test_backends()\n",
    "    print(\"\\n--- Summary of Backend Compatibility ---\")\n",
    "    for result in backend_results:\n",
    "        print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
