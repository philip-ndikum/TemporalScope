{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Validation in TemporalScope\n",
    "\n",
    "This tutorial demonstrates how to use TemporalScope's dataset validation utilities to check your data against research-backed heuristics. The validator helps assess whether your dataset meets common requirements for machine learning tasks, based on findings from key research papers.\n",
    "\n",
    "## Research Background\n",
    "\n",
    "The validation thresholds are derived from research papers that studied what makes datasets work well with different types of models:\n",
    "\n",
    "1. Grinsztajn et al. (2022):\n",
    "   - Minimum samples (≥ 3,000) for complex models\n",
    "   - Feature-to-sample ratio (d/n < 1/10)\n",
    "   - Categorical feature cardinality (≤ 20)\n",
    "\n",
    "2. Shwartz-Ziv and Armon (2021):\n",
    "   - Maximum samples (≤ 50,000) for medium-sized datasets\n",
    "   - Minimum features (≥ 4) for meaningful complexity\n",
    "\n",
    "3. Gorishniy et al. (2021):\n",
    "   - Maximum features (< 500) to avoid dimensionality issues\n",
    "   - Numerical feature uniqueness (≥ 10)\n",
    "\n",
    "These findings provide valuable guidelines, but remember they're recommendations, not strict rules. Your specific use case may require different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from temporalscope.datasets.dataset_validator import DatasetValidator\n",
    "\n",
    "# Create sample dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "data = {\n",
    "    'numeric_feature_1': np.random.normal(0, 1, n_samples),\n",
    "    'numeric_feature_2': np.random.uniform(0, 10, n_samples),\n",
    "    'categorical_feature': np.random.choice(['A', 'B', 'C'], n_samples),\n",
    "    'binary_feature': np.random.choice([0, 1], n_samples),\n",
    "    'target': np.random.choice([0, 1, 2], n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Validation\n",
    "\n",
    "Let's start by running all validation checks with default thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create validator with default settings\n",
    "validator = DatasetValidator()\n",
    "\n",
    "# Run validation checks\n",
    "results = validator.validate(df, target_col='target')\n",
    "\n",
    "# Print detailed report\n",
    "validator.print_report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Validation Thresholds\n",
    "\n",
    "The default thresholds are based on research findings but may not apply to all use cases. Let's customize them for our needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create validator with custom thresholds\n",
    "custom_validator = DatasetValidator(\n",
    "    min_samples=500,       # Minimum samples required\n",
    "    max_samples=5000,      # Maximum samples allowed\n",
    "    min_features=3,        # Minimum features required\n",
    "    max_features=10,       # Maximum features allowed\n",
    "    max_feature_ratio=0.2, # Maximum feature-to-sample ratio\n",
    "    min_unique_values=5,   # Minimum unique values for numerical features\n",
    "    max_categorical_values=5, # Maximum unique values for categorical features\n",
    "    class_imbalance_threshold=2.0  # Maximum class imbalance ratio\n",
    ")\n",
    "\n",
    "# Run validation with custom thresholds\n",
    "custom_results = custom_validator.validate(df, target_col='target')\n",
    "custom_validator.print_report(custom_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selective Validation\n",
    "\n",
    "You can choose to run only specific validation checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create validator with selected checks\n",
    "selective_validator = DatasetValidator(\n",
    "    checks_to_run=['sample_size', 'feature_count', 'class_balance']\n",
    ")\n",
    "\n",
    "# Run selected validation checks\n",
    "selective_results = selective_validator.validate(df, target_col='target')\n",
    "selective_validator.print_report(selective_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Different Backends\n",
    "\n",
    "The validator works with any DataFrame backend supported by Narwhals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import polars as pl\n",
    "\n",
    "# Convert to Polars DataFrame\n",
    "pl_df = pl.DataFrame(df)\n",
    "\n",
    "# Validate Polars DataFrame\n",
    "polars_results = validator.validate(pl_df, target_col='target')\n",
    "validator.print_report(polars_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Examples\n",
    "\n",
    "Here are some common ways to integrate dataset validation into your workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def validate_and_preprocess(df, target_col=None):\n",
    "    \"\"\"Validate dataset and handle common issues.\"\"\"\n",
    "    # Create validator with domain-specific thresholds\n",
    "    validator = DatasetValidator(\n",
    "        min_samples=1000,\n",
    "        max_feature_ratio=0.2,\n",
    "        class_imbalance_threshold=3.0\n",
    "    )\n",
    "    \n",
    "    # Run validation\n",
    "    results = validator.validate(df, target_col=target_col)\n",
    "    \n",
    "    # Handle validation results\n",
    "    if not results['sample_size'].passed:\n",
    "        print(\"Warning: Dataset size issues detected\")\n",
    "        print(f\"Details: {results['sample_size'].message}\")\n",
    "        \n",
    "    if target_col and not results['class_balance'].passed:\n",
    "        print(\"Warning: Class imbalance detected\")\n",
    "        print(f\"Class counts: {results['class_balance'].details['class_counts']}\")\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "validation_results = validate_and_preprocess(df, target_col='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Customize Thresholds**: Adjust validation thresholds based on your domain knowledge and specific requirements.\n",
    "\n",
    "2. **Handle Failures Gracefully**: Use validation results to inform preprocessing decisions:\n",
    "   - Sample size issues → Consider data collection or small dataset techniques\n",
    "   - Feature ratio issues → Consider feature selection or dimensionality reduction\n",
    "   - Class imbalance → Consider resampling or class weights\n",
    "\n",
    "3. **Regular Validation**: Run validation checks:\n",
    "   - When receiving new data\n",
    "   - After major preprocessing steps\n",
    "   - Before training models\n",
    "\n",
    "4. **Documentation**: Keep track of your validation thresholds and reasoning:\n",
    "```python\n",
    "# Example validation configuration\n",
    "validation_config = {\n",
    "    'min_samples': 1000,    # Based on model complexity\n",
    "    'max_features': 50,     # Based on available compute resources\n",
    "    'class_imbalance': 3.0  # Based on domain knowledge\n",
    "}\n",
    "```\n",
    "\n",
    "## Remember\n",
    "\n",
    "The validation thresholds are research-backed recommendations, not strict requirements. They should be:\n",
    "- Adjusted based on your specific use case\n",
    "- Used as guidelines, not hard rules\n",
    "- Documented with clear reasoning\n",
    "\n",
    "For more information, see the research papers referenced in the documentation:\n",
    "1. Grinsztajn et al. (2022) - Why do tree-based models still outperform deep learning on typical tabular data?\n",
    "2. Shwartz-Ziv and Armon (2021) - Tabular data: Deep learning is not all you need\n",
    "3. Gorishniy et al. (2021) - Revisiting deep learning models for tabular data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
