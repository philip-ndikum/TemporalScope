{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI Data Quality Checks in TemporalScope\n",
    "\n",
    "This tutorial demonstrates TemporalScope's data quality validation tools, designed for end-users who need to implement auditing and monitoring within automated model pipelines (e.g., Apache Airflow). While we provide the validation utilities, we expect end-users to integrate them into their specific Time Series XAI workflows.\n",
    "\n",
    "Key Use Cases:\n",
    "- Automated quality gates in production pipelines\n",
    "- Model training data validation\n",
    "- Continuous monitoring of data quality\n",
    "- Audit trails for XAI workflows\n",
    "\n",
    "## Engineering Design Overview\n",
    "\n",
    "The data quality tools follow a clear separation between validation and transformation phases:\n",
    "\n",
    "### Core Components\n",
    "\n",
    "1. **Validation Phase (fit)**:\n",
    "   - Validates TimeFrame or supported DataFrame type\n",
    "   - Ensures data meets quality requirements\n",
    "   - No Narwhals operations at this stage\n",
    "\n",
    "2. **Transformation Phase (transform)**:\n",
    "   - Uses pure Narwhals operations\n",
    "   - Performs configured validation checks\n",
    "   - Returns detailed validation results\n",
    "\n",
    "### Engineering Design Assumptions\n",
    "\n",
    "1. **Research-Backed Validation**:\n",
    "   - Thresholds from key research papers\n",
    "   - Customizable for domain requirements\n",
    "   - Clear documentation of sources\n",
    "\n",
    "2. **Backend Agnostic**:\n",
    "   - Validation in fit() before operations\n",
    "   - Pure Narwhals operations in transform()\n",
    "   - Clean separation of concerns\n",
    "\n",
    "3. **Pipeline Integration**:\n",
    "   - Monitoring and alerting capabilities\n",
    "   - Structured results for pipelines\n",
    "   - Support for workflow systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Validation with TimeFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from temporalscope.core.temporal_data_loader import TimeFrame\n",
    "from temporalscope.datasets.dataset_validator import DatasetValidator\n",
    "\n",
    "# Create sample dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Create data with numeric features (no special prefixes needed)\n",
    "data = {\n",
    "    'time': pd.date_range('2023-01-01', periods=n_samples),\n",
    "    'price': np.random.normal(0, 1, n_samples),\n",
    "    'volume': np.random.uniform(0, 10, n_samples),\n",
    "    'sentiment': np.random.choice([0, 1], n_samples),\n",
    "    'target': np.random.choice([0, 1, 2], n_samples)\n",
    "}\n",
    "\n",
    "# Create TimeFrame - it handles data validation internally\n",
    "tf = TimeFrame(pd.DataFrame(data), time_col='time', target_col='target')\n",
    "\n",
    "# Initialize validator\n",
    "validator = DatasetValidator()\n",
    "\n",
    "# Run validation checks\n",
    "results = validator.fit_transform(tf)\n",
    "\n",
    "# Print detailed report\n",
    "validator.print_report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Working with Different Backends\n",
    "\n",
    "The validator works with any DataFrame backend supported by Narwhals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import modin.pandas as mpd\n",
    "\n",
    "# Test with different backends\n",
    "for backend in [\"pandas\", \"polars\", \"modin\"]:\n",
    "    print(f\"\\nValidating with {backend} backend:\")\n",
    "    \n",
    "    # Create TimeFrame with appropriate backend\n",
    "    if backend == \"pandas\":\n",
    "        df = pd.DataFrame(data)\n",
    "    elif backend == \"polars\":\n",
    "        df = pl.DataFrame(data)\n",
    "    else:\n",
    "        df = mpd.DataFrame(data)\n",
    "    \n",
    "    # TimeFrame handles backend conversion\n",
    "    tf = TimeFrame(df, time_col='time', target_col='target')\n",
    "    \n",
    "    results = validator.fit_transform(tf)\n",
    "    print(f\"Validation Results ({backend}):\")\n",
    "    validator.print_report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Pipeline Integration\n",
    "\n",
    "Here's how to integrate validation into your automated pipelines (e.g., Apache Airflow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_for_pipeline(df, time_col, target_col):\n",
    "    \"\"\"Example Airflow task for data validation.\n",
    "    \n",
    "    This shows how to integrate validation into automated pipelines:\n",
    "    1. Create TimeFrame with proper configuration\n",
    "    2. Run validation checks\n",
    "    3. Get structured results for monitoring\n",
    "    4. Handle validation failures\n",
    "    \"\"\"\n",
    "    # Create TimeFrame\n",
    "    tf = TimeFrame(df, time_col=time_col, target_col=target_col)\n",
    "    \n",
    "    # Initialize validator with custom thresholds\n",
    "    validator = DatasetValidator(\n",
    "        min_samples=1000,\n",
    "        max_feature_ratio=0.2,\n",
    "        class_imbalance_threshold=3.0,\n",
    "        enable_warnings=True\n",
    "    )\n",
    "    \n",
    "    # Run validation\n",
    "    results = validator.fit_transform(tf)\n",
    "    \n",
    "    # Get structured results for monitoring\n",
    "    summary = ValidationResult.get_validation_summary(results)\n",
    "    failed = ValidationResult.get_failed_checks(results)\n",
    "    \n",
    "    if failed:\n",
    "        # Example: Push metrics to monitoring system\n",
    "        for check_name, result in failed.items():\n",
    "            log_entry = result.to_log_entry()\n",
    "            print(f\"Failed Check: {check_name}\")\n",
    "            print(f\"Details: {log_entry}\")\n",
    "            \n",
    "            # Example: Push to monitoring\n",
    "            # monitoring.push_metrics(\"data_validation\", log_entry)\n",
    "            \n",
    "            # Example: Fail pipeline on critical errors\n",
    "            if result.severity == \"ERROR\":\n",
    "                raise ValueError(f\"Critical validation failure: {check_name}\")\n",
    "    \n",
    "    return results, summary\n",
    "\n",
    "# Example usage\n",
    "results, summary = validate_for_pipeline(pd.DataFrame(data), time_col='time', target_col='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Details\n",
    "\n",
    "The validator handles different DataFrame backends through Narwhals operations:\n",
    "\n",
    "1. **LazyFrame (Dask/Polars)**:\n",
    "   - Uses collect() for scalar access\n",
    "   - Avoids direct indexing\n",
    "   - Handles lazy evaluation properly\n",
    "\n",
    "2. **PyArrow**:\n",
    "   - Uses nw.Int64 for numeric operations\n",
    "   - Handles comparisons through Narwhals\n",
    "   - Converts types before arithmetic operations\n",
    "\n",
    "3. **All Backends**:\n",
    "   - Uses @nw.narwhalify for backend conversions\n",
    "   - Pure Narwhals operations throughout\n",
    "   - Consistent behavior across supported types\n",
    "\n",
    "## Research-Backed Thresholds\n",
    "\n",
    "The validation thresholds are derived from key research:\n",
    "\n",
    "1. Grinsztajn et al. (2022):\n",
    "   - Minimum samples (≥ 3,000)\n",
    "   - Feature-to-sample ratio (d/n < 1/10)\n",
    "   - Categorical cardinality (≤ 20)\n",
    "\n",
    "2. Shwartz-Ziv and Armon (2021):\n",
    "   - Maximum samples (≤ 50,000)\n",
    "   - Minimum features (≥ 4)\n",
    "\n",
    "3. Gorishniy et al. (2021):\n",
    "   - Maximum features (< 500)\n",
    "   - Numerical uniqueness (≥ 10)\n",
    "\n",
    "These thresholds are recommendations that can be customized for your specific use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
