{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Narwhals Data Validation Patterns\n",
    "\n",
    "This notebook demonstrates essential patterns for validating data in AI/ML pipelines using Narwhals. These patterns ensure data quality and consistency across both training and inference:\n",
    "\n",
    "| Task | ✅ Good Pattern (Backend-Agnostic) | ❌ Bad Pattern (Backend-Specific) |\n",
    "|------|-----------------------------------|----------------------------------|\n",
    "| DataFrame Creation | `df = nw.from_native(df_pd)` | `df_pd = pd.DataFrame(data)` (without conversion) |\n",
    "| Column Access | `nw.col(\"feature\")` | `df[\"feature\"]` or `df.feature` |\n",
    "| Type Casting | `nw.col(\"x\").cast(nw.Float64())` | `df[\"x\"].astype(\"float64\")` |\n",
    "| Null Checking | `nw.col(\"x\").is_null().sum()` | `df[\"x\"].isnull().sum()` |\n",
    "| Mean Imputation | `nw.col(\"x\").fill_null(mean_val)` | `df[\"x\"].fillna(df[\"x\"].mean())` |\n",
    "| String Operations | `nw.col(\"x\").str.to_uppercase()` | `df[\"x\"].str.upper()` |\n",
    "\n",
    "We'll explore two fundamental ML workflow patterns:\n",
    "\n",
    "1. **Feature Validation (Eager)**\n",
    "   - Use `eager_only=True` for immediate validation results\n",
    "   - Return Python types for ML pipeline decisions\n",
    "   - Example: Checking numeric features before training\n",
    "\n",
    "2. **Feature Processing (Lazy)**\n",
    "   - Use lazy evaluation for transformation chains\n",
    "   - Let Narwhals optimize the operations\n",
    "   - Example: Converting features to ML-ready format\n",
    "\n",
    "The examples show how to handle common ML scenarios (missing values, mixed types, inconsistent categories) using proper Narwhals patterns that work across any DataFrame backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ada2bc",
   "metadata": {},
   "source": [
    "## Backend-Agnostic DataFrame Creation\n",
    "\n",
    "Narwhals provides a consistent interface across different DataFrame backends (Pandas, Polars, etc.). The key pattern for backend-agnostic code is:\n",
    "\n",
    "1. Create your DataFrame with any supported backend (e.g., Pandas)\n",
    "2. Convert to Narwhals format using `nw.from_native()`\n",
    "3. Use Narwhals operations that work across all backends\n",
    "\n",
    "This pattern ensures your code works regardless of the underlying DataFrame implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2ca4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────────────────────────┐\n",
       "| Narwhals DataFrame                    |\n",
       "| Use `.to_native` to see native output |\n",
       "└───────────────────────────────────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import narwhals as nw\n",
    "from narwhals.typing import FrameT  # Type hint for backend-agnostic DataFrames\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "\n",
    "# Create sample data with common ML data issues\n",
    "data = {\n",
    "    # Numeric features with different representations\n",
    "    'integer_feature': [1, 2, None, 4, 5],           # Has null\n",
    "    'float_feature': [1.5, 2.5, 3.5, None, 5.5],    # Has null\n",
    "    'string_number': ['1.0', '2.0', 'bad', '4.0', '5.0'],  # Has invalid value\n",
    "    \n",
    "    # Categorical features with inconsistencies\n",
    "    'category_clean': ['A', 'B', 'A', 'C', 'B'],\n",
    "    'category_messy': ['a', 'B', None, 'c', 'b'],   # Mixed case + null\n",
    "    \n",
    "    # Target variable\n",
    "    'target': [0, 1, 1, 0, 1]                       # Binary classification\n",
    "}\n",
    "\n",
    "# Pattern: Backend-Agnostic Conversion\n",
    "df_pd = pd.DataFrame(data)           # Create with any backend\n",
    "df = nw.from_native(df_pd)          # Convert to Narwhals format\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5b90b",
   "metadata": {},
   "source": [
    "## Pattern 1: Simple ML Type Validation Functions\n",
    "\n",
    "In ML workflows, we commonly need to validate two types of features:\n",
    "1. Numeric features (can be converted to float, handle nulls)\n",
    "2. Categorical features (consistent categories, handle case sensitivity)\n",
    "\n",
    "Let's create simple validation functions that work across any backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea98014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with Pandas backend:\n",
      "\n",
      "Numeric validation:\n",
      "integer_feature: {'valid': True, 'null_count': np.int64(1), 'mean': np.float64(3.0)}\n",
      "string_number: {'valid': False, 'error': \"could not convert string to float: 'bad'\"}\n",
      "\n",
      "Categorical validation:\n",
      "category_clean: {'valid': True, 'null_count': np.int64(0), 'unique_count': np.int64(3), 'n_categories': np.int64(3)}\n",
      "category_messy: {'valid': True, 'null_count': np.int64(1), 'unique_count': np.int64(5), 'n_categories': np.int64(5)}\n"
     ]
    }
   ],
   "source": [
    "@nw.narwhalify(eager_only=True)\n",
    "def validate_numeric_column(df: FrameT, column: str) -> Dict[str, Any]:\n",
    "    \"\"\"Validate if a column can be used as numeric feature.\n",
    "    \n",
    "    Common ML checks:\n",
    "    - Can convert to float\n",
    "    - Count of nulls\n",
    "    - Basic statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try float conversion\n",
    "        stats = df.select([\n",
    "            nw.col(column)\n",
    "               .cast(nw.Float64())\n",
    "               .mean()\n",
    "               .alias(\"mean\"),\n",
    "            nw.col(column)\n",
    "               .is_null()\n",
    "               .sum()\n",
    "               .alias(\"nulls\")\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"valid\": True,\n",
    "            \"null_count\": stats[\"nulls\"].item(),\n",
    "            \"mean\": stats[\"mean\"].item()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"valid\": False,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "@nw.narwhalify(eager_only=True)\n",
    "def validate_categorical_column(df: FrameT, column: str) -> Dict[str, Any]:\n",
    "    \"\"\"Validate if a column can be used as categorical feature.\n",
    "    \n",
    "    Common ML checks:\n",
    "    - Unique categories\n",
    "    - Null handling\n",
    "    - Case consistency\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get stats using Narwhals operations only\n",
    "        stats = df.select([\n",
    "            nw.col(column)\n",
    "               .cast(nw.String())\n",
    "               .n_unique()\n",
    "               .alias(\"unique\"),\n",
    "            nw.col(column)\n",
    "               .is_null()\n",
    "               .sum()\n",
    "               .alias(\"nulls\")\n",
    "        ])\n",
    "        \n",
    "        # Get categories using Narwhals operations\n",
    "        categories = df.select([\n",
    "            nw.col(column)\n",
    "               .cast(nw.String())\n",
    "               .alias(column)\n",
    "        ]).unique()\n",
    "        \n",
    "        return {\n",
    "            \"valid\": True,\n",
    "            \"null_count\": stats[\"nulls\"].item(),\n",
    "            \"unique_count\": stats[\"unique\"].item(),\n",
    "            \"n_categories\": categories.select([nw.col(column).count()]).item()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"valid\": False,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Test with Pandas backend\n",
    "print(\"Testing with Pandas backend:\")\n",
    "print(\"\\nNumeric validation:\")\n",
    "print(\"integer_feature:\", validate_numeric_column(df, \"integer_feature\"))\n",
    "print(\"string_number:\", validate_numeric_column(df, \"string_number\"))\n",
    "\n",
    "print(\"\\nCategorical validation:\")\n",
    "print(\"category_clean:\", validate_categorical_column(df, \"category_clean\"))\n",
    "print(\"category_messy:\", validate_categorical_column(df, \"category_messy\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46cbea",
   "metadata": {},
   "source": [
    "### Next we'll show these same functions working with Polars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593a6da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with Polars backend:\n",
      "\n",
      "Numeric validation:\n",
      "integer_feature: {'valid': True, 'null_count': 1, 'mean': 3.0}\n",
      "string_number: {'valid': False, 'error': 'conversion from `str` to `f64` failed in column \\'string_number\\' for 1 out of 5 values: [\"bad\"]'}\n",
      "\n",
      "Categorical validation:\n",
      "category_clean: {'valid': True, 'null_count': 0, 'unique_count': 3, 'n_categories': 3}\n",
      "category_messy: {'valid': True, 'null_count': 1, 'unique_count': 5, 'n_categories': 4}\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Create Polars DataFrame\n",
    "df_pl = pl.DataFrame(data)\n",
    "df_pl_nw = nw.from_native(df_pl)\n",
    "\n",
    "print(\"Testing with Polars backend:\")\n",
    "print(\"\\nNumeric validation:\")\n",
    "print(\"integer_feature:\", validate_numeric_column(df_pl_nw, \"integer_feature\"))\n",
    "print(\"string_number:\", validate_numeric_column(df_pl_nw, \"string_number\"))\n",
    "\n",
    "print(\"\\nCategorical validation:\")\n",
    "print(\"category_clean:\", validate_categorical_column(df_pl_nw, \"category_clean\"))\n",
    "print(\"category_messy:\", validate_categorical_column(df_pl_nw, \"category_messy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c3d84",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "The validation functions work consistently across backends with some notable differences:\n",
    "\n",
    "1. **Numeric Validation**\n",
    "   - Both backends detect invalid numeric values (\"bad\" in string_number)\n",
    "   - Error messages differ but convey the same information\n",
    "   - Null counting and mean calculation work identically\n",
    "\n",
    "2. **Categorical Validation**\n",
    "   - Both backends count nulls consistently\n",
    "   - Category counting differs slightly:\n",
    "     * Pandas counts None as a category (5 categories)\n",
    "     * Polars excludes None (4 categories)\n",
    "   - This backend difference is important to note for ML pipelines\n",
    "\n",
    "## Pattern 2: Feature Processing\n",
    "\n",
    "Now that we can validate features, let's look at processing them for ML. This uses lazy evaluation since we're transforming data, not validating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "782f688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas backend:\n",
      "\n",
      "Processing numeric feature:\n",
      "   integer_feature\n",
      "0              1.0\n",
      "1              2.0\n",
      "2              3.0\n",
      "3              4.0\n",
      "4              5.0\n",
      "\n",
      "Processing categorical feature:\n",
      "  category_messy\n",
      "0              A\n",
      "1              B\n",
      "2           NONE\n",
      "3              C\n",
      "4              B\n",
      "\n",
      "Polars backend:\n",
      "\n",
      "Processing numeric feature:\n",
      "shape: (5, 1)\n",
      "┌─────────────────┐\n",
      "│ integer_feature │\n",
      "│ ---             │\n",
      "│ f64             │\n",
      "╞═════════════════╡\n",
      "│ 1.0             │\n",
      "│ 2.0             │\n",
      "│ 3.0             │\n",
      "│ 4.0             │\n",
      "│ 5.0             │\n",
      "└─────────────────┘\n",
      "\n",
      "Processing categorical feature:\n",
      "shape: (5, 1)\n",
      "┌────────────────┐\n",
      "│ category_messy │\n",
      "│ ---            │\n",
      "│ str            │\n",
      "╞════════════════╡\n",
      "│ A              │\n",
      "│ B              │\n",
      "│ UNKNOWN        │\n",
      "│ C              │\n",
      "│ B              │\n",
      "└────────────────┘\n"
     ]
    }
   ],
   "source": [
    "@nw.narwhalify\n",
    "def process_numeric_feature(df: FrameT, column: str) -> FrameT:\n",
    "    \"\"\"Process a numeric feature for ML.\n",
    "    \n",
    "    Common ML transformations:\n",
    "    - Convert to float\n",
    "    - Fill nulls with mean\n",
    "    - Standardize format\n",
    "    \"\"\"\n",
    "    # Get mean first\n",
    "    mean_val = df.select([\n",
    "        nw.col(column)\n",
    "           .cast(nw.Float64())\n",
    "           .mean()\n",
    "    ]).item()\n",
    "    \n",
    "    # Then use it for filling nulls\n",
    "    return df.select([\n",
    "        nw.col(column)\n",
    "           .cast(nw.Float64())\n",
    "           .fill_null(mean_val)\n",
    "           .alias(column)\n",
    "    ])\n",
    "\n",
    "@nw.narwhalify\n",
    "def process_categorical_feature(df: FrameT, column: str) -> FrameT:\n",
    "    \"\"\"Process a categorical feature for ML.\n",
    "    \n",
    "    Common ML transformations:\n",
    "    - Standardize case\n",
    "    - Fill nulls with UNKNOWN\n",
    "    - Consistent string format\n",
    "    \"\"\"\n",
    "    return df.select([\n",
    "        nw.col(column)\n",
    "           .cast(nw.String())\n",
    "           .str.to_uppercase()\n",
    "           .fill_null(\"UNKNOWN\")\n",
    "           .alias(column)\n",
    "    ])\n",
    "\n",
    "# Test with both backends\n",
    "print(\"Pandas backend:\")\n",
    "print(\"\\nProcessing numeric feature:\")\n",
    "numeric_result = process_numeric_feature(df, \"integer_feature\")\n",
    "print(numeric_result)\n",
    "\n",
    "print(\"\\nProcessing categorical feature:\")\n",
    "categorical_result = process_categorical_feature(df, \"category_messy\")\n",
    "print(categorical_result)\n",
    "\n",
    "print(\"\\nPolars backend:\")\n",
    "print(\"\\nProcessing numeric feature:\")\n",
    "numeric_result_pl = process_numeric_feature(df_pl_nw, \"integer_feature\")\n",
    "print(numeric_result_pl)\n",
    "\n",
    "print(\"\\nProcessing categorical feature:\")\n",
    "categorical_result_pl = process_categorical_feature(df_pl_nw, \"category_messy\")\n",
    "print(categorical_result_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474a99d",
   "metadata": {},
   "source": [
    "# Summary: Core Narwhals Patterns\n",
    "\n",
    "| Pattern | When to Use | Why This Pattern | Example Use Cases |\n",
    "|---------|-------------|------------------|-------------------|\n",
    "| **Eager Validation** <br> (`eager_only=True`) | • Need immediate results <br> • Returning Python types <br> • Checking data quality | • Validation needs results now <br> • Can't defer error checking <br> • Must verify before processing | • Type compatibility checks <br> • Null value detection <br> • Category validation |\n",
    "| **Lazy Transformation** <br> (default) | • Chaining operations <br> • Data transformations <br> • Feature engineering | • Let Narwhals optimize <br> • Better memory usage <br> • More efficient pipelines | • Type conversions <br> • Missing value imputation <br> • Feature standardization |\n",
    "\n",
    "### Typical Validation Workflows\n",
    "\n",
    "1. **Data Quality Validation (Eager)**\n",
    "   - Use when immediate validation results needed\n",
    "   - Return Python types for pipeline decisions\n",
    "   - Example: Checking numeric features before training\n",
    "\n",
    "2. **Data Transformation (Lazy)**\n",
    "   - Use for transformation chains\n",
    "   - Let Narwhals optimize operations\n",
    "   - Example: Converting features to ML-ready format\n",
    "\n",
    "These patterns ensure your data validation code:\n",
    "- Works consistently across DataFrame backends\n",
    "- Uses appropriate evaluation strategies\n",
    "- Follows best practices for validation\n",
    "- Maintains code clarity and purpose\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
